# -*- coding:utf-8 -*-
"""
âœï¸Author     : ğŸˆ
â²ï¸Time       : 2024/5/25
ğŸ“„File       : n04-CSSä¼ªå…ƒç´ åçˆ¬.py
â„¹ï¸Description: ç®€çŸ­æè¿°è¯¥æ–‡ä»¶çš„ä¸»è¦åŠŸèƒ½æˆ–ç›®çš„

ç»ƒä¹ ç›®æ ‡ï¼šhttp://www.spiderbuf.cn/n04/
"""

import time

import requests
from lxml import etree


def get_page(url, headers=None, retries=3):
    default_headers = headers or {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0 Win64 x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36', }

    for attempt in range(retries):
        try:
            response = requests.get(url, headers=default_headers, timeout=10)
            response.raise_for_status()  # å¦‚æœä¸æ˜¯200çŠ¶æ€ç è¯·æ±‚ï¼Œåˆ™æŠ›å‡ºHTTPErroré”™è¯¯
            return response.text
        except requests.exceptions.RequestException as e:  # é€šç”¨å¼‚å¸¸æ•è·
            print(f"Error making request to {url}: {e}. Attempt {attempt + 1} of {retries}.")
            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…ä¸€æ®µæ—¶é—´
    return None


def parse_page(html):
    """
    ä½¿ç”¨ lxml çš„ etree è§£æ HTML
    :param html: ç½‘é¡µçš„æºä»£ç æ•°æ®
    :return: None
    """
    # åœ¨ç½‘é¡µä¸­åˆ°åˆ°ä¼ªç±»çš„æ ·å¼è¡¨
    pseudo_class = {
        "abcdef::before": "7",
        "abcdef::after": "5",
        "ghijkl::before": "8",
        "ghijkl::after": "9",
        "mnopqr::before": "9",
        "mnopqr::after": "1",
        "uvwxyz::before": "1",
        "uvwxyz::after": "4",
        "yzabcd::before": "2",
        "yzabcd::after": "6",
        "efghij::before": "3",
        "efghij::after": "2",
        "klmnop::before": "5",
        "klmnop::after": "7",
        "qrstuv::before": "4",
        "qrstuv::after": "3",
        "wxyzab::before": "6",
        "wxyzab::after": "0",
        "cdefgh::before": "0",
        "cdefgh::after": "8",
        "hijklm::after": "6",
        "opqrst::after": "0",
        "uvwxab::after": "3",
        "cdijkl::after": "8",
        "pqrmno::after": "1",
        "stuvwx::after": "4",
        "pkenmc::after": "7",
        "tcwdsk::after": "9",
        "mkrtyu::after": "5",
        "umdrtk::after": "2",
    }
    tree = etree.HTML(html)
    title_list = tree.xpath('//div[@class="container"]/div/div/h2/text()')
    scores_list = tree.xpath('//div[@class="container"]/div/div/div[2]/span[2]/@class')
    # å°†scores_beforeå’Œscores_afterçš„å€¼å»æ„å»ºå®Œæ•´çš„å­—å…¸çš„é”®ï¼Œç„¶åä»¥é”®å»pseudo_classæ‰¾å¯¹åº”çš„å€¼
    for i, item in enumerate(scores_list):
        scores_before = item.split()[0] + '::before'
        scores_after = item.split()[1] + '::after'
        scores = f'{pseudo_class.get(scores_before)}.{pseudo_class.get(scores_after)}'
        print(f'{title_list[i]}: {scores}')


def main():
    page_url = 'http://www.spiderbuf.cn/n04/'
    html_data = get_page(page_url)
    if html_data:
        parse_page(html_data)
    else:
        print(f"Failed to retrieve or parse page: {page_url}")


if __name__ == '__main__':
    main()
