# -*- coding:utf-8 -*-
"""
âœï¸Author     : ğŸˆ
â²ï¸Time       : 2024/5/29
ğŸ“„File       : new.py
â„¹ï¸Description: ç®€çŸ­æè¿°è¯¥æ–‡ä»¶çš„ä¸»è¦åŠŸèƒ½æˆ–ç›®çš„

è¿™é‡Œæˆ‘æƒ³ä½¿ç”¨è¿›ç¨‹æ± æ¥åˆ›å»º6ä¸ªè¿›ç¨‹ï¼ŒæŠ“å–6ä¸ªé¡µé¢ï¼Œä¸”æ¯ä¸ªè¿›ç¨‹ä¸­åœ¨ä½¿ç”¨çº¿ç¨‹æ± æ¥ä¸‹è½½å›¾ç‰‡
"""
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from urllib3.util.retry import Retry
import requests
from requests.adapters import HTTPAdapter

# é…ç½®å¸¸é‡
FOLDER = 'img'
TAG_ID = 12
TOTAL_PAGE = 6  # æ€»é¡µæ•°

# åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
folder_path = Path(FOLDER)
folder_path.mkdir(parents=True, exist_ok=True)

# é…ç½®è¯·æ±‚é‡è¯•ç­–ç•¥
retries = Retry(
    total=3,  # æ€»é‡è¯•æ¬¡æ•°
    backoff_factor=1,  # æŒ‡æ•°é€€é¿å› å­
    allowed_methods=frozenset(['GET', 'POST']),  # å…è®¸é‡è¯•çš„HTTPæ–¹æ³•
)
adapter = HTTPAdapter(max_retries=retries)
session = requests.Session()
session.mount('http://', adapter)
session.mount('https://', adapter)

# è®¾ç½®è¯·æ±‚å¤´
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) upupoo-wallpaper-shop/0.0.1 Chrome/80.0.3987.165 Electron/8.2.5 Safari/537.36',
})


def get_page(method, url, **kwargs):
    """
    å‘é€HTTPè¯·æ±‚è·å–å“åº”å¯¹è±¡ã€‚

    Args:
        method (str): HTTPæ–¹æ³•ï¼Œå¦‚`GET`ã€`POST`ç­‰ã€‚
        url (str): è¦è¯·æ±‚çš„URLã€‚
        **kwargs: requestæ”¯æŒçš„æ‰€æœ‰å‚æ•°ã€‚

    Returns:
        requests.Response: HTTPå“åº”å¯¹è±¡ã€‚å¦‚æœå‡ºé”™ï¼Œè¿”å›Noneã€‚
    """
    try:
        response = session.request(method, url, timeout=10, **kwargs)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        print(f"Error making {method} request to {url}: {e}")
        return None


def get_index_page(page):
    """
    è·å–æŒ‡å®šé¡µç çš„ç´¢å¼•é¡µæ•°æ®ã€‚

    Args:
        page (int): é¡µç ã€‚

    Returns:
        requests.Response: HTTPå“åº”å¯¹è±¡ã€‚
    """
    url = 'https://pcwallpaper.upupoo.com/wallpaper/lists'
    data = {
        "current": page,
        "size": 28,
        "total": 239311,
        "type": 0,
        "tagId": TAG_ID,
        "sort": 0,
        "resolution": 0,
        "hairtail": 0
    }
    return get_page('POST', url, json=data)


def parse(json_data):
    """
    è§£æJSONæ•°æ®ï¼Œç”Ÿæˆå›¾ç‰‡IDå’ŒURLã€‚

    Args:
        json_data (dict): JSONæ•°æ®ã€‚

    Yields:
        tuple: å›¾ç‰‡IDå’Œå›¾ç‰‡URLã€‚
    """
    records = json_data.get('data', {}).get('records', [])
    for info in records:
        paper_id = info['paper_id']
        img_url = info['img_url']
        new_img_url = img_url.replace('listCover.jpg', 'previewFix.jpg')
        yield paper_id, new_img_url


def download(data):
    """
    ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°ã€‚

    Args:
        data (tuple): å›¾ç‰‡IDå’Œå›¾ç‰‡URLã€‚
    """
    name, url = data
    response = get_page('GET', url)
    if response:
        file_path = folder_path / f'{name}.jpg'
        with file_path.open('wb') as f:
            f.write(response.content)
        print(f'Successful -> {url}')
    else:
        print(f'Failed to download -> {url}')


def start_thread_pool(func, iterable):
    """
    å¯åŠ¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œä»»åŠ¡ã€‚

    Args:
        func (callable): è¦å¹¶è¡Œæ‰§è¡Œçš„å‡½æ•°ã€‚
        iterable (iterable): ä»»åŠ¡çš„å¯è¿­ä»£å¯¹è±¡ã€‚
    """
    with ThreadPoolExecutor(max_workers=12) as executor:
        executor.map(func, iterable)


def main():
    """
    ä¸»å‡½æ•°ï¼Œå¯åŠ¨è¿›ç¨‹æ± è·å–æ•°æ®ï¼Œå¹¶å¯åŠ¨çº¿ç¨‹æ± ä¸‹è½½å›¾ç‰‡ã€‚
    """
    with ProcessPoolExecutor(max_workers=6) as process_executor:
        # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨ï¼Œè·å–æ¯ä¸€é¡µçš„æ•°æ®ï¼Œå¹¶è§£æå›¾ç‰‡ä¿¡æ¯
        img_tasks = (
            img for html in process_executor.map(get_index_page, range(1, TOTAL_PAGE + 1))
            if html is not None
            for img in parse(html.json())
        )
        # å¯åŠ¨çº¿ç¨‹æ± ä¸‹è½½å›¾ç‰‡
        start_thread_pool(download, img_tasks)


if __name__ == '__main__':
    main()
