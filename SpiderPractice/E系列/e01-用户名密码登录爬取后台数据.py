# _*_ coding: utf-8 _*_
"""
@ ğŸ˜€Author     : ğŸˆ
@ â²ï¸Time       : 2023å¹´12æœˆ30
@ ğŸ“„File       : e01-ç”¨æˆ·åå¯†ç ç™»å½•çˆ¬å–åå°æ•°æ®.py
@ â„¹ï¸Description:
ç»ƒä¹ ç›®æ ‡ï¼šhttp://www.spiderbuf.cn/e01/

ä¸€èˆ¬æˆ‘ä»¬åœ¨å¤„ç†éœ€è¦ç™»å½•çš„é¡µé¢æ—¶ï¼Œéƒ½è¦å…ˆç¡®ä¿å¼€å‘è€…å·¥å…·ä¸­çš„ä¿ç•™æ—¥å¿—å·²å‹¾é€‰ï¼Œè¿™æ˜¯å› ä¸ºåˆ·æ–°é¡µé¢æˆ–è¿›è¡Œå…¶ä»–æ“ä½œæ—¶ï¼Œæµè§ˆå™¨å¯èƒ½ä¼šæ¸…ç©ºä¹‹å‰çš„è¯·æ±‚è®°å½•ï¼Œå¯¼è‡´æ— æ³•æ•è·å’ŒæŸ¥çœ‹æ‰€éœ€çš„è¯·æ±‚ä¿¡æ¯ã€‚

æµç¨‹ï¼š
    - æ‰“å¼€å¼€å‘è€…å·¥å…·å¹¶å‹¾é€‰â€œä¿ç•™æ—¥å¿—â€ã€‚
    - ç‚¹å‡»ç™»å½•æŒ‰é’®ã€‚
    - æŸ¥çœ‹å’Œåˆ†æç½‘ç»œè¯·æ±‚ï¼š
        -åœ¨â€œNetworkâ€é¢æ¿ä¸­æ‰¾åˆ°ç™»å½•è¯·æ±‚ï¼ˆé€šå¸¸æ˜¯POSTè¯·æ±‚ï¼‰ã€‚
        -æŸ¥çœ‹è¯·æ±‚çš„URLã€è¯·æ±‚å¤´ã€è¯·æ±‚ä½“å’Œå“åº”æ•°æ®ã€‚
        -å¤åˆ¶éœ€è¦çš„è¯·æ±‚ä¿¡æ¯ï¼Œç”¨äºæ¨¡æ‹Ÿç™»å½•è¯·æ±‚ã€‚

æ‰¾åˆ°ç™»å½•çš„é¡µé¢: http://www.spiderbuf.cn/e01/login  POST 307
requestsä¼šè‡ªåŠ¨å¤„ç†é‡å®šå‘ï¼Œæ‰€ä»¥é€šè¿‡postè¯·æ±‚ç™»å½•é¡µé¢é“¾æ¥å³å¯
"""
# å¯¼å…¥éœ€è¦çš„åº“
import os.path

import requests
from lxml import etree


def get_page(url, headers=None, data=None, **kwargs):
    default_headers = headers or {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    }

    try:
        response = requests.post(url, headers=default_headers, data=data, timeout=10, **kwargs)
        response.raise_for_status()  # å¦‚æœä¸æ˜¯2xxçŠ¶æ€ç è¯·æ±‚ï¼Œåˆ™æŠ›å‡ºHTTPErroré”™è¯¯
        return response.text  # è¿”å›å“åº”å¯¹è±¡
    except requests.exceptions.RequestException as e:  # é€šç”¨å¼‚å¸¸æ•è·
        print(f"Error making request to {url}: {e}")
        return None


def parse(html):
    """
    è§£ææ•°æ®
    :param html: ç½‘é¡µçš„æºä»£ç 
    :return: page_data_list: ä¸€é¡µçš„æ•°æ®ä¿¡æ¯
    """
    dom_tree = etree.HTML(html)
    # trå…ƒç´ ï¼Œä¸€å…±50æ¡
    trs = dom_tree.xpath('//table[@class="table"]/tbody/tr')
    page_data_list = []
    for tr in trs:
        ranking = tr.xpath('./td[1]/text()')[0]
        value = tr.xpath('./td[2]/text()')[0]
        enterprise_information = tr.xpath('./td[3]/text()')[0]
        ceo_name = tr.xpath('./td[4]/text()')[0]
        profession = tr.xpath('./td[5]/text()')[0]
        row_data = ','.join([ranking, value, enterprise_information, ceo_name, profession, '\n'])
        page_data_list.append(row_data)
    return page_data_list


def save_data(data_list, file_name='e01èƒ¡æ¶¦ä¸­å›½500å¼º.txt'):
    """æ•°æ®ä¿å­˜"""
    folder_name = 'datas'
    if not os.path.exists(folder_name):
        os.mkdir(folder_name)
    path = os.path.join(folder_name, file_name)  # å®Œæ•´æ–‡ä»¶è·¯å¾„
    with open(path, mode='w', encoding='utf-8') as f:
        f.writelines(data_list)


if __name__ == '__main__':
    login_data = {'username': 'admin', 'password': '123456'}
    login_url = 'http://www.spiderbuf.cn/e01/login'
    html_data = get_page(login_url, data=login_data)
    page_data = parse(html_data)
    save_data(page_data)
