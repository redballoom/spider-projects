# -*- coding:utf-8 -*-
"""
âœï¸Author     : ğŸˆ
â²ï¸Time       : 2024/5/25
ğŸ“„File       : n05-CSS Sprites ï¼ˆé›ªç¢§å›¾ï¼‰åçˆ¬.py
â„¹ï¸Description: ç®€çŸ­æè¿°è¯¥æ–‡ä»¶çš„ä¸»è¦åŠŸèƒ½æˆ–ç›®çš„

åŒä¼ªç±»çš„ç›¸è¯†ï¼Œä¸è¿‡æ˜¯ç›´æ¥å»è·å–å®Œæ•´çš„ç±»ï¼Œä¸éœ€è¦åƒä¼ªç±»é‚£æ ·éœ€è¦æ‹¼æ¥ï¼Œä¸”ç½‘é¡µä¸­æ²¡æœ‰æä¾›å¯¹åº”çš„å€¼ï¼Œ
åªèƒ½æ‰¾åˆ°é›ªç¢§å›¾ï¼Œçœ‹çœ‹å…¶å†…æœ‰å“ªäº›æ•°æ®ï¼Œç„¶åä¸€ä¸ªä¸€ä¸ªåœ¨ç½‘é¡µä¸­è¯•å‡ºæ¥ï¼Œåœ¨æ„å»ºå¥½æ•°æ®

é›ªç¢§å›¾ï¼š [0,1,2,3,4,5,6,7,8,9]
ä»–ä»¬æ¯ä¸ªå€¼éƒ½å¯ä»¥åœ¨ç½‘é¡µä¸­æ‰¾åˆ°å¯¹åº”çš„ç±»å±æ€§ï¼Œè·å–ç±»å±æ€§å¯¹åº”çš„å€¼æ„å»ºæˆå­—å…¸ã€‚
"""
# å¯¼å…¥éœ€è¦çš„åº“
import os
import csv

import requests
from lxml import etree

save_directory = 'datas'
os.makedirs(save_directory, exist_ok=True)  # exist_ok=True å¦‚æœç›®å½•å·²ç»å­˜åœ¨ï¼Œåˆ™ä¸å¼•å‘é”™è¯¯, Falseåˆ™åä¹‹


def get_page(url, headers=None, retries=3):
    default_headers = headers or {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    }

    for _ in range(retries):
        try:
            response = requests.get(url, headers=default_headers, timeout=10)
            response.raise_for_status()  # å¦‚æœä¸æ˜¯200çŠ¶æ€ç è¯·æ±‚ï¼Œåˆ™æŠ›å‡ºHTTPErroré”™è¯¯
            return response.text
        except requests.exceptions.RequestException as e:  # é€šç”¨å¼‚å¸¸æ•è·
            print(f"Error making request to {url}: {e}")
    return None


def lxml_parse(html):
    """
    ä½¿ç”¨ lxml çš„ etree è§£æ HTML
    :param html: ä¸€é¡µçš„ç½‘é¡µæºä»£ç æ•°æ®
    :return data: è§£æåçš„ä¸€é¡µå­—å…¸æ•°æ®åˆ—è¡¨
    """
    sprite_chart = {
        'sprite abcdef': '0',
        'sprite ghijkl': '1',
        'sprite mnopqr': '2',
        'sprite uvwxyz': '3',
        'sprite yzabcd': '4',
        'sprite efghij': '5',
        'sprite klmnop': '6',
        'sprite wxyzab': '8',
        'sprite cdefgh': '9'
    }
    data = []
    dom_tree = etree.HTML(html)
    divs = dom_tree.xpath('//div[@class="container"]/div/div')
    for div in divs:
        title = div.xpath('./h2/text()')[0]
        ranking = div.xpath('./p[1]/text()')[0].replace('æ’åï¼š', '')
        value = div.xpath('./p[2]/span/@class')
        value = ''.join(map(lambda i: sprite_chart[i], value))
        ceo_name = div.xpath('./p[3]/text()')[0].replace('CEOï¼š', '')
        profession = div.xpath('./p[4]/text()')[0].replace('è¡Œä¸šï¼š', '')

        dic = {'ä¼ä¸š': title,
               'æ’å': ranking,
               'ä¼ä¸šä¼°å€¼(äº¿å…ƒ)': value,
               'CEO': ceo_name,
               'è¡Œä¸š': profession}
        print(dic)
        data.append(dic)
    return data


def save_data(datas, file_name='n05èƒ¡æ¶¦ä¸­å›½500å¼º.csv'):
    """æ•°æ®ä¿å­˜"""
    fieldnames = ['ä¼ä¸š', 'æ’å', 'ä¼ä¸šä¼°å€¼(äº¿å…ƒ)', 'CEO', 'è¡Œä¸š']
    path = os.path.join(save_directory, file_name)

    with open(path, 'w', newline='', encoding='utf-8') as w_f:
        writer = csv.DictWriter(w_f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(datas)


def main():
    url = 'http://www.spiderbuf.cn/n05/'
    my_headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36',
        'Referer': 'http://www.spiderbuf.cn/list'
    }
    html_data = get_page(url, headers=my_headers)
    if html_data:
        data_list = lxml_parse(html_data)
        save_data(data_list)
    print('All Done!')


if __name__ == '__main__':
    main()