# -*- coding:utf-8 -*-
"""
âœï¸Author     : ğŸˆ
â²ï¸Time       : 2024/5/19
ğŸ“„File       : new_jijian.py
â„¹ï¸Description: çˆ¬å–æç®€å£çº¸çš„å£çº¸ï¼Œæ›´ä¼˜é›…çš„å®ç°æ–¹æ³•

"""
import time
import json
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue

import requests
from loguru import logger
import execjs


def general_request(method, url, headers=None, **kwargs):
    """çœŸæ­£çš„é€šç”¨è¯·æ±‚æ–¹æ³•ã€‚

    :param method: è¯·æ±‚æ–¹å¼ [``GET``, ``POST`` ......]
    :param url: è¯·æ±‚åœ°å€
    :param headers: è¯·æ±‚å¤´
    :return: responseå“åº”å¯¹è±¡
    """
    default_headers = headers or {
        "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                       "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36")
    }

    try:
        response = requests.request(method, url, headers=default_headers, **kwargs)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        logger.error(f"An error occurred during request: {e}")
        return None


def generate_api_data(page):
    """æ ¹æ®pageé¡µç ç”Ÿæˆè‡ªå®šä¹‰çš„æ•°æ®è½½è·ä¿¡æ¯ï¼Œä»¥ä¾›POSTè¯·æ±‚æ—¶æºå¸¦"""
    return {"size": 24, "current": page, "sort": 0, "category": 0,
            "resolution": 0, "color": 0, "categoryId": 0, "ratio": 0}


def decrypt_result(data):
    """
    ä½¿ç”¨ JavaScript ä»£ç å¯¹ç»“æœè¿›è¡Œè§£å¯†ã€‚

    :param data: åŒ…å«åŠ å¯†æ•°æ®çš„å­—å…¸æ•°æ®.
    :return: å¦‚æœæˆåŠŸè§£å¯†ï¼Œåˆ™ä¸ºè§£å¯†åçš„æ•°æ®ï¼Œå¦åˆ™ä¸ºNoneã€‚
    """
    try:
        result = data['result']  # åŠ å¯†çš„æ•°æ®
        with open('new_jijian.js', mode='r', encoding='utf-8') as f:
            js_code = f.read()
        # ä½¿ç”¨execjsåº“ç¼–è¯‘JavaScriptä»£ç å¹¶é€šè¿‡decrypt_codeå‡½æ•°æ‰§è¡Œè§£å¯†
        json_data = execjs.compile(js_code).call('decrypt_code', result)
        data = json.loads(json_data)
        return data
    except Exception as e:
        logger.error(f"An error occurred during decryption: {e}")
        return None


def download_image(pic_url, pic_id, download_dir="images2"):
    """
    ä»ç»™å®šçš„ pic_url ä¸‹è½½å›¾ç‰‡ï¼Œå¹¶ä»¥ç»™å®šçš„ pic_id ä¿å­˜ã€‚

    :param pic_url: ä¸‹è½½å›¾åƒçš„url
    :param pic_id: ä¿å­˜å›¾åƒçš„åç§°
    :param download_dir: ä¿å­˜å›¾åƒçš„ç›®å½•ã€‚
    :return:
    """
    headers = {
        "Referer": "https://bz.zzzmh.cn/",  # 403 é˜²ç›—é“¾å¤„ç†
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    }

    try:
        os.makedirs(download_dir, exist_ok=True)  # ç›®å½•å­˜åœ¨æ—¶ä¸å¼•å‘æŠ¥é”™
        response = general_request('GET', pic_url, headers=headers, stream=True)  # å¼€å¯åˆ†å—è¯·æ±‚
        if response:
            img_file_path = os.path.join(download_dir, f"{pic_id}.jpg")
            # æ‰“å¼€æ–‡ä»¶ï¼ŒæŒ‰å—å†™å…¥ä»¥èŠ‚çœå†…å­˜
            with open(img_file_path, 'wb') as f:
                for chunk in response.iter_content(1024 * 512):  # è®¾ç½®ä¸€å— â‰ˆ 0.5 MB
                    f.write(chunk)
            logger.info(f"Downloaded image {pic_id} from {pic_url}")
        else:
            logger.error(f"Failed to download image {pic_id} from {pic_url}: {response.status_code}")
    except Exception as e:
        logger.error(f"An error occurred during downloading image {pic_id}: {e}")


def parse(data, download_queue):
    """
    ä»è§£å¯†åçš„æ•°æ®ä¸­è§£æå‡ºæ„æˆå›¾ç‰‡é“¾æ¥çš„å‚æ•°ï¼Œå†æ‹¼æ¥å‡ºå®Œæ•´å›¾ç‰‡é“¾æ¥ï¼Œå¹¶æ”¾å…¥ä¸‹è½½é˜Ÿåˆ—ã€‚

    :param data: è¦è§£æçš„æ•°æ®
    :param download_queue: ç”¨äºä¿å­˜ä¸‹è½½ä»»åŠ¡çš„é˜Ÿåˆ—
    :return:
    """
    try:
        for item in data['list']:
            pic_id = item.get('i')
            pic_t = item.get('t')
            # æ„å»ºå®Œæ•´çš„å£çº¸ä¸‹è½½é“¾æ¥
            pic_url = f'https://api.zzzmh.cn/bz/v3/getUrl/{pic_id}{pic_t}9'
            # å°†ä¸‹è½½ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­
            download_queue.put((pic_url, pic_id))
    except Exception as e:
        logger.error(f"An error occurred during parsing: {e}")


def download_worker(download_queue):
    """
    å·¥ä½œå‡½æ•°ï¼Œç”¨äºä»ä¸‹è½½é˜Ÿåˆ—ä¸­å–ä»»åŠ¡å¹¶ä¸‹è½½å›¾ç‰‡ã€‚

    :param download_queue: ä¿å­˜ä¸‹è½½ä»»åŠ¡çš„é˜Ÿåˆ—
    """
    while not download_queue.empty():
        try:
            pic_url, pic_id = download_queue.get()
            download_image(pic_url, pic_id)
            # å‘ŠçŸ¥é˜Ÿåˆ—æ­¤ä»»åŠ¡å·²å®Œæˆ
            download_queue.task_done()
        except download_queue.Empty:
            break


def main():
    download_queue = Queue()  # åˆå§‹åŒ–é˜Ÿåˆ—
    api_url = "https://api.zzzmh.cn/bz/v3/getData"

    for page in range(1, 2):  # 1é¡µçš„å›¾ç‰‡
        data_args = generate_api_data(page)
        page_response = general_request('POST', api_url, json=data_args, timeout=10)  # æ¥å£çš„å“åº”å¯¹è±¡
        if page_response:
            decrypt_data = decrypt_result(page_response.json())
            if decrypt_data:  # å¦‚æœæœ‰è§£å¯†æ•°æ®
                parse(decrypt_data, download_queue)
            else:
                logger.info("decrypt_data is None. æ³¨æ„ä½ å¯èƒ½è¢«åçˆ¬é™åˆ¶äº†!")

    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = [executor.submit(download_worker, download_queue) for _ in range(6)]

        for future in as_completed(futures):
            future.result()  # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    download_queue.join()  # ç­‰å¾…é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰ä»»åŠ¡å®Œæˆ


if __name__ == '__main__':
    s = time.time()
    main()
    print(f'è€—æ—¶ {time.time() - s}')  # è€—æ—¶ 89.2294065952301
